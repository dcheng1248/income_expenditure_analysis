{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_statement(page):\n",
    "    text = page.extract_text()\n",
    "    if not 'Bank Statement Nr.' in text:\n",
    "        return pd.DataFrame(columns = [\"Merchant\", \"Category\", \"Date\", \"Amount\"])\n",
    "    # get date of statement\n",
    "    lines = text.split(\"\\n\")\n",
    "    date = lines[4].split()[1]\n",
    "\n",
    "    # remove first 5 lines of text and reassemble text\n",
    "    lines = lines[6:]\n",
    "    text = '\\n'.join(lines)\n",
    "\n",
    "    # find entry of each income or expenditure\n",
    "    entries = [i for i in text.split(\"€\") if i]\n",
    "    entries = [list(filter(None,i.split(\"\\n\"))) for i in entries if i]\n",
    "    entries = entries[:-1]\n",
    "\n",
    "    # remove movement between spaces\n",
    "    remove_list = []\n",
    "    for entry in entries:\n",
    "        if len(entry) < 3:\n",
    "            remove_list.append(entry)\n",
    "    for entry in remove_list:\n",
    "        entries.remove(entry)\n",
    "\n",
    "    #  remove irrelevant information and parse transaction date and amount\n",
    "    for entry in entries:\n",
    "        if entry[1].startswith('Mastercard • '):\n",
    "            entry[1] = entry[1].replace('Mastercard • ','')\n",
    "        for item in entry[2:]:\n",
    "            if not item.startswith('Value Date '):\n",
    "                entry.remove(item)\n",
    "        entry[2] = entry[2][21:]\n",
    "        splitted = entry[2].split()\n",
    "        entry.pop(2)\n",
    "        entry.append(splitted[0])\n",
    "        entry.append(splitted[1])\n",
    "        entry[3] = entry[3].replace('.','')\n",
    "        entry[3] = entry[3].replace(',','.')\n",
    "        entry[3] = entry[3].replace('+','')\n",
    "        if len(entry) != 4:\n",
    "            print(entry)\n",
    "\n",
    "    # now only 4 columns are left, merchant/payee, category, date and amount\n",
    "    # add to pandas\n",
    "    entries = np.array(entries)\n",
    "    df = pd.DataFrame(entries, columns = [\"Merchant\", \"Category\", \"Date\", \"Amount\"])\n",
    "    df[\"Amount\"] = df[\"Amount\"].astype('float')\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tm/6h1pp8k1183g0792lm0b20s00000gp/T/ipykernel_57717/3374457670.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, read_statement(page)])\n",
      "/var/folders/tm/6h1pp8k1183g0792lm0b20s00000gp/T/ipykernel_57717/3374457670.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, read_statement(page)])\n",
      "/var/folders/tm/6h1pp8k1183g0792lm0b20s00000gp/T/ipykernel_57717/3374457670.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, read_statement(page)])\n",
      "/var/folders/tm/6h1pp8k1183g0792lm0b20s00000gp/T/ipykernel_57717/3374457670.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, read_statement(page)])\n",
      "/var/folders/tm/6h1pp8k1183g0792lm0b20s00000gp/T/ipykernel_57717/3374457670.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, read_statement(page)])\n",
      "/var/folders/tm/6h1pp8k1183g0792lm0b20s00000gp/T/ipykernel_57717/3374457670.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, read_statement(page)])\n",
      "/var/folders/tm/6h1pp8k1183g0792lm0b20s00000gp/T/ipykernel_57717/3374457670.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, read_statement(page)])\n",
      "/var/folders/tm/6h1pp8k1183g0792lm0b20s00000gp/T/ipykernel_57717/3374457670.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, read_statement(page)])\n",
      "/var/folders/tm/6h1pp8k1183g0792lm0b20s00000gp/T/ipykernel_57717/3374457670.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, read_statement(page)])\n",
      "/var/folders/tm/6h1pp8k1183g0792lm0b20s00000gp/T/ipykernel_57717/3374457670.py:14: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  summary_income = income.groupby(\"Merchant\", as_index = False).agg({\"Amount\": sum})\n"
     ]
    }
   ],
   "source": [
    "reader = PyPDF2.PdfReader(\"statement-2023-09.pdf\")\n",
    "df = pd.DataFrame(columns = [\"Merchant\", \"Category\", \"Date\", \"Amount\"])\n",
    "for page in reader.pages:\n",
    "    df = pd.concat([df, read_statement(page)])\n",
    "\n",
    "# fix some category assignment issues\n",
    "df.loc[df[\"Merchant\"].str.contains('STEAMGAMES'), \"Category\"] = 'Games'\n",
    "df.loc[df[\"Merchant\"].str.contains('APPLE'), \"Category\"] = 'Games'\n",
    "df.loc[df[\"Merchant\"].str.contains('AMAZON'), \"Category\"] = 'Amazon'\n",
    "df.loc[df[\"Merchant\"].str.contains('UBER \\*EATS'), \"Category\"] = 'Bars & Restaurants'\n",
    "\n",
    "# summarize income\n",
    "income = df[df[\"Amount\"] > 0]\n",
    "summary_income = income.groupby(\"Merchant\", as_index = False).agg({\"Amount\": sum})\n",
    "total_income = income[\"Amount\"].sum()\n",
    "\n",
    "# summarize expenditure\n",
    "expenditure = df[df[\"Amount\"] < 0]\n",
    "total_expenditure = -expenditure[\"Amount\"].sum()\n",
    "summary_expenditure = expenditure.groupby(\"Category\", as_index = False).sum()[[\"Category\", \"Amount\"]]\n",
    "summary_expenditure[\"Amount\"] = -summary_expenditure[\"Amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total income: 3363.51\n",
      "Breakdown:\n",
      "                        Merchant   Amount\n",
      "0  AMAZON PAYMENTS EUROPE S.C.A.    17.99\n",
      "1     Boehringer Ingelheim Fonds  2201.85\n",
      "2           Dana - Maria Grozavu    97.68\n",
      "3                           EMBL   345.79\n",
      "4                     HENNER-GMC   491.40\n",
      "5                    Yidan Jiang   208.80\n",
      "\n",
      "Total expenditure: 2005.14\n",
      "Breakdown:\n",
      "               Category  Amount\n",
      "0                   ATM  200.00\n",
      "1                Amazon   58.13\n",
      "2    Bars & Restaurants  209.61\n",
      "3     Business Expenses   15.90\n",
      "4         Direct Debits  331.62\n",
      "5                 Games  123.45\n",
      "6             Groceries  250.35\n",
      "7  Multimedia & Telecom    7.99\n",
      "8    Outgoing Transfers  796.30\n",
      "9              Shopping   11.79\n",
      "\n",
      "Expenditures from category Direct Debits\n",
      "                                            Merchant       Category  \\\n",
      "0                          Rhein-Neckar-Verkehr GmbH  Direct Debits   \n",
      "3                         EnBW Energie Bad-Wuertt AG  Direct Debits   \n",
      "0                                      GC re Getsafe  Direct Debits   \n",
      "3                              Drillisch Online GmbH  Direct Debits   \n",
      "4                          Rundfunk ARD, ZDF, DRadio  Direct Debits   \n",
      "1                                 Vodafone West GmbH  Direct Debits   \n",
      "4  Reit- und Fahrverein Heidelberg-Handschuhsheim...  Direct Debits   \n",
      "\n",
      "         Date  Amount  \n",
      "0  01.09.2023  -34.30  \n",
      "3  08.09.2023 -103.00  \n",
      "0  11.09.2023   -3.25  \n",
      "3  14.09.2023   -9.99  \n",
      "4  15.09.2023  -55.08  \n",
      "1  18.09.2023   -6.00  \n",
      "4  20.09.2023 -120.00  \n"
     ]
    }
   ],
   "source": [
    "print(\"Total income:\", total_income)\n",
    "print(\"Breakdown:\")\n",
    "print(summary_income)\n",
    "print()\n",
    "print(\"Total expenditure:\", total_expenditure)\n",
    "print(\"Breakdown:\")\n",
    "print(summary_expenditure)\n",
    "print()\n",
    "\n",
    "category = \"Direct Debits\"\n",
    "print(\"Expenditures from category\", category)\n",
    "print(expenditure[expenditure[\"Category\"] == category])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
